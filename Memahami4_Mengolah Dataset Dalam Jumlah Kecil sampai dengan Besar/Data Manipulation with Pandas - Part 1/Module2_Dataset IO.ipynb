{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**START**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module : Dataset I/O**\n",
    "\n",
    "*Pada bagian ini kamu akan mempelajari bagaimana membaca dan menyimpan dataset dari dan ke beberapa tipe file dengan menggunakan pandas.* "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pendahuluan**\n",
    "\n",
    "*Memangnya file apa saja sih yang bisa dibaca oleh Pandas?*\n",
    "\n",
    "*Pandas menyediakan berbagai method untuk membaca file tersebut hanya dengan dipanggil method itu, code yang lebih simple dan loading yang lebih, tentu saja output nya dapat berupa Series atau Dataframe.*\n",
    "\n",
    "*Terdapat sangat banyak file yang dapat dibaca/dapat disimpan oleh Pandas, tapi ada beberapa file yang paling umum dan sering digunakan oleh praktisi data seperti berikut ini:*\n",
    "\n",
    "1. *CSV (Comma Separated Values), antar data dalam satu baris dipisahkan oleh comma, \",\".*\n",
    "2. *TSV (Tab Separated Values), antar data dalam satu baris dipisahkan oleh \"Tab\".*\n",
    "3. *Excel*\n",
    "4. *Google BigQuery*\n",
    "5. *SQL Query*\n",
    "6. *JSON (Java Script Object Notation)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Dataset - CSV dan TSV**\n",
    "\n",
    "*CSV dan TSV pada hakikatnya adalah tipe data text dengan perbedaan terletak pada pemisah antar data dalam satu baris.*\n",
    "\n",
    "1. **Pada file CSV**, antar data dalam satu baris dipisahkan oleh comma, \",\".\n",
    "2. **Pada file TSV** antar data dalam satu baris dipisahkan oleh \"Tab\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fungsi .read_csv()** digunakan untuk membaca file yang value-nya dipisahkan oleh comma (default), terkadang pemisah value-nya bisa di set ‘\\t’ untuk file tsv (tab separated values).*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Membaca file CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# File CSV\n",
    "df_csv = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/sample_csv.csv')\n",
    "print(df_csv.head(3)) # Menampilkan 3 data teratas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Membaca file TSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n"
     ]
    }
   ],
   "source": [
    "# File TSV\n",
    "df_tsv = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv', sep='\\t')\n",
    "print(df_tsv.head(3)) # Menampilkan 3 data teratas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Dataset - Excel**\n",
    "\n",
    "*File Excel dengan ekstensi *.xls atau *.xlsx cukup banyak digunakan dalam menyimpan data. Pandas juga memiliki fitur untuk membaca file excel.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fungsi .read_excel()** digunakan untuk membaca file excel menjadi dataframe pandas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "3   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0520   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n",
      "3  BRAND_B        12      450000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# File xlsx dengan data di sheet \"test\"\n",
    "df_excel = pd.read_excel('https://storage.googleapis.com/dqlab-dataset/sample_excel.xlsx', sheet_name='test')\n",
    "print(df_excel.head(4)) # Menampilkan 4 data teratas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Dataset - JSON**\n",
    "\n",
    "***Method .read_json()** digunakan untuk membaca URL API yang formatnya JSON dan mengubahnya menjadi dataframe pandas. Method ini dapat digunakan seperti yang dicontohkan berikut ini:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data          dt          ts\n",
      "0  {'location': 'US', 'confirmed': 3363056, 'deat...  07-14-2020  1594684800\n",
      "1  {'location': 'Brazil', 'confirmed': 1884967, '...  07-14-2020  1594684800\n",
      "2  {'location': 'India', 'confirmed': 906752, 'de...  07-14-2020  1594684800\n",
      "3  {'location': 'Russia', 'confirmed': 732547, 'd...  07-14-2020  1594684800\n",
      "4  {'location': 'Peru', 'confirmed': 330123, 'dea...  07-14-2020  1594684800\n",
      "5  {'location': 'Chile', 'confirmed': 317657, 'de...  07-14-2020  1594684800\n",
      "6  {'location': 'Mexico', 'confirmed': 304435, 'd...  07-14-2020  1594684800\n",
      "7  {'location': 'United Kingdom', 'confirmed': 29...  07-14-2020  1594684800\n",
      "8  {'location': 'South Africa', 'confirmed': 2877...  07-14-2020  1594684800\n",
      "9  {'location': 'Iran', 'confirmed': 259652, 'dea...  07-14-2020  1594684800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# File JSON\n",
    "url = 'https://storage.googleapis.com/dqlab-dataset/covid2019-api-herokuapp-v2.json'\n",
    "df_json = pd.read_json(url)\n",
    "print(df_json.head(10)) # Menampilkan 10 data teratas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Dataset - SQL**\n",
    "\n",
    "*Fungsi **.read_sql()** atau **.read_sql_query()** digunakan untuk membaca query dari database dan translate menjadi pandas dataframe, contoh case ini database **sqlite**.*\n",
    "\n",
    "*hasil tidak akan keluar karena tidak memiliki akses*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Membuat koneksi ke database financial di https:/relational.fit.cvut.cz/dataset/Financial*\n",
    "2. *Melakukan query sql untuk membaca tabel loan*\n",
    "3. *Membaca tabel menggunakan .read_sql_query()*\n",
    "4. *Membaca tabel menggunakan .read_sql()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Membuat koneksi ke database financial di https:/relational.fit.cvut.cz/dataset/Financial\n",
    "my_conn = mysql.connector.connect(host=\"relational.fit.cvut.cz\",\n",
    "                                  port=3306,\n",
    "                                  user='guest',\n",
    "                                  passwd=\"relational\",\n",
    "                                  database=\"financial\",\n",
    "                                  use_pure=True)\n",
    "# Buatlah query sql untuk membaca tabel loan\n",
    "my_query = \"\"\"\n",
    "SELECT *\n",
    "FROM loan;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan .read_sql_query untuk membaca tabel loan tersebut\n",
    "df_loan = pd.read_sql_query(my_query, my_conn)\n",
    "# Tampilkan 5 data teratas\n",
    "df_loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan .read_sql\n",
    "df_loan = pd.read_sql(my_query,my_conn)\n",
    "# Tampilkan 5 data teratas\n",
    "df_loan.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Dataset - Google BigQuery**\n",
    "\n",
    "*Untuk data yang besar (big data), umumnya digunakan Google BigQuery. Layanan ini dapat digunakan jika telah memiliki Google BigQuery account.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fungsi **.read_gbq()** digunakan untuk membaca Google BigQuery table menjadi dataframe pandas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Buat query\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM 'bigquery-public-data.covid19_jhu_csse_eu.summary'\n",
    "LIMIT 1000;\n",
    "\"\"\"\n",
    "# Baca data dari Google Big Query\n",
    "df_covid19_eu_summary = pd.read_gbd(query, project_id='XXXXXX')\n",
    "# Tampilkan 5 data teratas\n",
    "df_covid19_eu_summary\n",
    "\n",
    "# project_id=\"XXXXXXXX\" adalah ID dari Google BigQuery account."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write Dataset**\n",
    "\n",
    "*Dalam bekerja sebagai data scientist/analis setelah dilakukan data cleaning dataset yang sudah rapi tentunya disimpan terlebih dahulu ke dalam media penyimpanan.*  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pandas menyediakan fitur demikian secara ringkas melalui penerapan method pada dataframe/series yang ditabelkan berikut ini:*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method**\n",
    "\n",
    "**.to_csv()**\n",
    "\n",
    "*→ digunakan untuk export dataframe kembali ke csv atau tsv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "df.to_csv(\"csv1.csv\", index=False)\n",
    "\n",
    "# TSV\n",
    "df.to_csv(\"tsv1.tsv\", index=False, sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.to_clipboard()**\n",
    "\n",
    "*→ export dataframe menjadi bahan copy jadi nanti bisa tinggal klik paste di excel atau google sheets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.to_excel()**\n",
    "\n",
    "*→ export dataframe menjadi file excel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.to_excel(\"xlsx1.xlsx\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.to_gbq()**\n",
    "\n",
    "*→ export dataframe menjadi table di Google BigQuery*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_gbq(\"temp.test\", project_id=\"XXXXXX\", if_exists=\"fail\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**temp**: nama dataset,\n",
    "\n",
    "**test**: nama table\n",
    "\n",
    "**if_exists**: ketika tabel dengan dataset.table_name yang sama sudah ada, apa action yang ingin dilakukan\n",
    "\n",
    "(**\"fail\"**: tidak melakukan apa-apa,\n",
    "\n",
    " **\"replace'**: membuang tabel yang sudah ada dan mengganti yang baru,\n",
    "\n",
    " **\"append\"**: menambah baris di tabel tersebut dengan data yang baru\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Head & Tail**\n",
    "\n",
    "*Seperti yang telah dipelajari sebelumnya bahwa ada method .head yang diterapkan pada suatu variabel bertipe pandas dataframe/series.*\n",
    "\n",
    "1. *Method **.head** ditujukan untuk membatasi tampilan jumlah baris teratas dari dataset.* \n",
    "2. *Method **.tail** ditujukan untuk membatasi jumlah baris terbawah dari dataset.*\n",
    "\n",
    "*Secara umum kedua method ini memiliki bentuk*\n",
    "\n",
    "a. [nama_dataframe].head(n)\n",
    "\n",
    "b. [nama_dataframe].tail(n)\n",
    "\n",
    "*dengan n merupakan jumlah baris yang akan ditampilkan, jika tidak disebutkan n = 5 (sebagai nilai default dari n).* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiga data teratas:\n",
      "    order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n",
      "Tiga data terbawah:\n",
      "      order_id  order_date  customer_id      city          province product_id  \\\n",
      "98    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3354   \n",
      "99    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3357   \n",
      "100   1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P0422   \n",
      "\n",
      "       brand  quantity  item_price  \n",
      "98   BRAND_S        24      450000  \n",
      "99   BRAND_S        24      450000  \n",
      "100  BRAND_B         4     1325000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/sample_csv.csv')\n",
    "# Tampilkan 3 data teratas\n",
    "print(\"Tiga data teratas:\\n\", df.head(3))\n",
    "# Tampilkan 3 data terbawah\n",
    "print(\"Tiga data terbawah:\\n\", df.tail(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lakukan analisis dengan menggunakan BigQuery karena ada beberapa data BigQuery public datasets yang informasinya akurat dan sudah banyak data point-nya sehingga sudah bisa digunakan.*\n",
    "\n",
    "*Tapi masalahnya, ada beberapa data adhoc yang bergantung tim lain yang belum terlalu melek data dan datanya masih disimpan dalam bentuk CSV.*\n",
    "\n",
    "*Bagaimana langkah efektif yang dapat diambil untuk melakukan analisis gabungan data dari BigQuery dan CSV?*\n",
    "\n",
    "***Hint**: coba explore BigQuery public datasets dulu, kamu akan dapati data size yang besar (>1juta baris), akan susah kalau harus di export dan dilakukan analisis di excel.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *(b) Upload data CSV ke BigQuery, lakukan analisis di dalam BigQuery/export to pandas menggunakan pd.read_gbq*\n",
    "\n",
    "2. *(c) Export data BigQuery menggunakan pd.read_gbq as dataframe, kemudian baca file csv menggunakan pd.read_csv dan akhirnya melakukan analisis gabungan di python*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of Module**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dfae695991f40f7f711b859ebe4404a578ce2940a1c2f7058c1cb98bd497b2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
