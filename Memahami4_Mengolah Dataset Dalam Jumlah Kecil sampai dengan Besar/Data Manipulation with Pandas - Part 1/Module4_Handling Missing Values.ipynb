{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**START**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module : Handling Missing Values**\n",
    "\n",
    "*Pada bagian ini kamu akan berhadapan dengan real world data yang mana akan terdapat data yang hilang (missing value). Untuk menanganinya dapat dibuang saja atau diisi dengan nilai statistik tertentu.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pendahuluan**\n",
    "\n",
    "*“Aksara, saya barusan kirim email lagi ya berisi link seputar handling missing values untuk Pandas. Kamu bisa belajar lebih lengkap di sana bersama isi modul.”*\n",
    "\n",
    "*“Siap!”*\n",
    "\n",
    "*Tanpa menunggu lagi, aku mengecek link yang diberikan Andra:*\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspeksi Missing Value**\n",
    "\n",
    "*Value yang hilang/tidak lengkap dari dataframe akan membuat analisis atau model prediksi yang dibuat menjadi tidak akurat dan mengakibatkan keputusan salah yang diambil. Terdapat beberapa cara untuk mengatasi data yang hilang/tidak lengkap tersebut.*\n",
    "\n",
    "*Data COVID-19 yang akan digunakan ini diambil dari google big query, tetapi sudah disediakan datasetnya dalam format csv dengan nama https://storage.googleapis.com/dqlab-dataset/datacovid19.csv. Ini adalah studi kasus untuk meng-handle missing value. Bagaimanakah langkah-langkahnya?*\n",
    "\n",
    "*Di pandas data yang hilang umumnya direpresentasikan dengan **NaN**.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Langkah pertama**, harus tahu kolom mana yang terdapat data hilang dan berapa banyak dengan cara:*\n",
    "\n",
    "1. *Cara 1: menerapkan method **.info()***\n",
    "2. *Cara 2: mengetahui berapa banyak nilai hilang dari tiap kolom di dataset tersebut dengan menerapkan chaining method pada dataframe yaitu **.isna().sum().** Method .isna() digunakan untuk mengecek berapa data yang bernilai NaN dan .sum() menjumlahkannya secara default untuk masing-masing kolom dataframe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   province_state  960 non-null    object \n",
      " 1   country_region  1000 non-null   object \n",
      " 2   date            1000 non-null   object \n",
      " 3   latitude        874 non-null    float64\n",
      " 4   longitude       874 non-null    float64\n",
      " 5   location_geom   874 non-null    object \n",
      " 6   confirmed       1000 non-null   int64  \n",
      " 7   deaths          999 non-null    float64\n",
      " 8   recovered       999 non-null    float64\n",
      " 9   active          949 non-null    float64\n",
      " 10  fips            949 non-null    float64\n",
      " 11  admin2          842 non-null    object \n",
      " 12  combined_key    0 non-null      float64\n",
      "dtypes: float64(7), int64(1), object(5)\n",
      "memory usage: 101.7+ KB\n",
      "None\n",
      "\n",
      "Jumlah missing value per kolom:\n",
      " province_state      40\n",
      "country_region       0\n",
      "date                 0\n",
      "latitude           126\n",
      "longitude          126\n",
      "location_geom      126\n",
      "confirmed            0\n",
      "deaths               1\n",
      "recovered            1\n",
      "active              51\n",
      "fips                51\n",
      "admin2             158\n",
      "combined_key      1000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/datacovid19.csv')\n",
    "\n",
    "# Cetak info dari df\n",
    "print(df.info())\n",
    "\n",
    "# Cetak jumlah missing value di setiap kolom\n",
    "mv = df.isna().sum()\n",
    "print('\\nJumlah missing value per kolom:\\n', mv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treatment untuk Missing Value - Part 1**\n",
    "\n",
    "*Terdapat beberapa cara untuk mengatasi missing value, antara lain:*\n",
    "\n",
    "1. ***dibiarkan saja,***\n",
    "2. ***hapus value itu, atau***\n",
    "3. ***isi value tersebut dengan value yang lain (biasanya interpolasi, mean, median, etc)***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE** :* \n",
    "\n",
    "1. *Sebelum melakukan action ke missing value pada data covid diatas, sebaiknya tampilkan beberapa row teratas dari dataset itu*\n",
    "2. *dan dilihat kembali jumlah missing value tiap kolomnya.*\n",
    "3. *agar dapat ditelaah terlebih dahulu.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_geom</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>fips</th>\n",
       "      <th>admin2</th>\n",
       "      <th>combined_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>01-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>18-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>17-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>31-01-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>19-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>22-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>25-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>27-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>03-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  province_state country_region      date  latitude  longitude location_geom  \\\n",
       "0            NaN             UK  01-02-20       NaN        NaN           NaN   \n",
       "1            NaN             UK  18-02-20       NaN        NaN           NaN   \n",
       "2            NaN             UK  17-02-20       NaN        NaN           NaN   \n",
       "3            NaN             UK  31-01-20       NaN        NaN           NaN   \n",
       "4            NaN             UK  19-02-20       NaN        NaN           NaN   \n",
       "5            NaN             UK  22-02-20       NaN        NaN           NaN   \n",
       "6            NaN             UK  25-02-20       NaN        NaN           NaN   \n",
       "7            NaN             UK  16-02-20       NaN        NaN           NaN   \n",
       "8            NaN             UK  27-02-20       NaN        NaN           NaN   \n",
       "9            NaN             UK  03-02-20       NaN        NaN           NaN   \n",
       "\n",
       "   confirmed  deaths  recovered  active  fips admin2  combined_key  \n",
       "0          2     0.0        0.0     NaN   NaN    NaN           NaN  \n",
       "1          9     0.0        8.0     NaN   NaN    NaN           NaN  \n",
       "2          9     0.0        8.0     NaN   NaN    NaN           NaN  \n",
       "3          2     NaN        NaN     NaN   NaN    NaN           NaN  \n",
       "4          9     0.0        8.0     NaN   NaN    NaN           NaN  \n",
       "5          9     0.0        8.0     NaN   NaN    NaN           NaN  \n",
       "6         13     0.0        8.0     NaN   NaN    NaN           NaN  \n",
       "7          9     0.0        8.0     NaN   NaN    NaN           NaN  \n",
       "8         15     0.0        8.0     NaN   NaN    NaN           NaN  \n",
       "9          2     0.0        0.0     NaN   NaN    NaN           NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "province_state      40\n",
       "country_region       0\n",
       "date                 0\n",
       "latitude           126\n",
       "longitude          126\n",
       "location_geom      126\n",
       "confirmed            0\n",
       "deaths               1\n",
       "recovered            1\n",
       "active              51\n",
       "fips                51\n",
       "admin2             158\n",
       "combined_key      1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\")\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hanya kolom combine_key yang keseluruhan barisnya adalah missing value (1000 buah), sementara kolom country_region, date, dan confirmed tidak memiliki missing value. Untuk kolom lainnya terdapat beragam jumlah missing value. Apa yang dapat dilakukan?*\n",
    "\n",
    "**PENTING**\n",
    "\n",
    "*Untuk memahami mana kolom yang akan di **treatment dengan tiga perlakukan di atas lihat nature dari data terlebih dahulu**. Contohnya pada kolom death dan recovered jika ada yang missing value maka kemungkinan terbesarnya adalah tidak ada meninggal atau sembuh pada hari tersebut.* \n",
    "\n",
    "*Untuk kolom yang seluruhnya missing yaitu combined_key dapat dibuang saja satu kolom itu karena tidak ada data yang dapat diketahui dari kolom tersebut.*\n",
    "\n",
    "*Sementara, kolom yang lainnya bagaimana? Misal ambil kolom province_stat, missing value-nya dapat terjadi bahwa tidak dilaporkan itu berasal dari daerah mana di negara itu. Dapat mengisi misal dengan string 'unknown' karena tahu kolom tersebut bertipe data string.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treatment untuk Missing Value - Part 2**\n",
    "\n",
    "*Sekarang dapat menerapkan dua aksi yaitu*\n",
    "\n",
    "1. ***Membiarkannya saja***\n",
    "2. ***Menghapus kolom***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Treatment **pertama** (membiarkannya saja) seperti pada kolom confirmed, death, dan recovered. Akan tetapi jika tidak ada yang terkonfirmasi, meninggal dan sembuh sebenarnya dapat menukar value ini dengan angka nol. Meskipun ini lebih make sense dalam representasi datanya, tetapi untuk sub bab ini ketiga kolom tersebut diasumsikan dibiarkan memiliki nilai missing value.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Treatment **kedua** yaitu dengan menghapus kolom, yang mana ini digunakan jika seluruh kolom dari dataset yang dipunyai semua barisnya adalah missing value. Untuk itu dapat menerapkan method .dropna() pada dataframe, bagaimana caranya?*\n",
    "\n",
    "**nama_dataframe.dropna(axis=1, how=\"all\")**\n",
    "\n",
    "*Pada method .dropna() ada dua keyword argumen yang harus diisikan yaitu axis dan how. Keyword axis digunakan untuk menentukan arah dataframe yang akan dibuang angka 1 untuk menyatakan kolom (column-based) atau dapat ditulis dalam string \"column\". Jika digunakan angka 0 berarti itu dalam searah index (row-based) atau dapat ditulis dalam string \"index\".*\n",
    "\n",
    "*Sementara, keyword how digunakan untuk bagaimana cara membuangnya. Opsi yang dapat diterimanya (dalam string) adalah*\n",
    "\n",
    "1. *\"all\" artinya jika seluruh data di satu/beberapa kolom atau di satu/beberapa baris adalah missing value.*\n",
    "2. *\"any\" artinya jika memiliki 1 saja data yang hilang maka buanglah baris/kolom tersebut.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran awal df: 1000 baris, 13 kolom.\n",
      "Ukuran df setelah buang kolom dengan seluruh data missing: 1000 baris, 12 kolom.\n",
      "Ukuran df setelah dibuang baris yang memiliki sekurangnya 1 missing value: 746 baris, 12 kolom.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\")\n",
    "# Cetak ukuran awal dataframe\n",
    "print(\"Ukuran awal df: %d baris, %d kolom.\" % df.shape)\n",
    "\n",
    "# Drop kolom yang seluruhnya missing value dan cetak ukurannya\n",
    "df = df.dropna(axis=1, how='all')\n",
    "print(\"Ukuran df setelah buang kolom dengan seluruh data missing: %d baris, %d kolom.\" % df.shape)\n",
    "\n",
    "# Drop baris jika ada satu saja data yang missing dan cetak ukurannya\n",
    "df = df.dropna(axis=0, how='any')\n",
    "print(\"Ukuran df setelah dibuang baris yang memiliki sekurangnya 1 missing value: %d baris, %d kolom.\" % df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treatment untuk Missing Value - Part 3**\n",
    "\n",
    "*Sekarang, akan melakukan treatment ketiga untuk melakukan handle missing value pada dataframe. Treatment ini dilakukan dengan cara mengisi missing value dengan nilai lain, yang dapat berupa :*\n",
    "\n",
    "1. *nilai statistik seperti mean atau median*\n",
    "2. *interpolasi data*\n",
    "3. *text tertentu*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Akan mulai pada kolom yang missing yang tipe datanya adalah berupa object. Kolom tersebut adalah province_state, karena tidak tahu secara persis province_state mana yang dimaksud, bisa menempatkan string \"unknown\" sebagai substitusi missing value. Meskipun keduanya berarti sama-sama tidak tahu tetapi berbeda dalam representasi datanya.*\n",
    "\n",
    "*Untuk melakukan hal demikian dapat menggunakan **method .fillna()** pada kolom dataframe yang dimaksud.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value awal:\n",
      " [nan 'US' 'Guam' 'Iowa']\n",
      "Unique value setelah fillna:\n",
      " ['unknown_province_state' 'US' 'Guam' 'Iowa']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\")\n",
    "# Cetak unique value pada kolom province_state\n",
    "print(\"Unique value awal:\\n\", df['province_state'].unique())\n",
    "\n",
    "# Ganti missing value dengan string \"unknown_province_state\"\n",
    "df['province_state'] = df['province_state'].fillna('unknown_province_state')\n",
    "# Cetak kembali unique value pada kolom province_state\n",
    "print(\"Unique value setelah fillna:\\n\", df['province_state'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Terlihat bahwa unique value di kolom \"province_state\" yang semula ada nan telah berubah menjadi \"unknown_province_state\".* "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treatment untuk Missing Value - Part 4**\n",
    "\n",
    "*Masih melanjutkan bagaimana melakukan handle missing value tentunya dengan jalan mengganti missing value dengan nilai lainnya. Pada bab sebelumnya telah mengganti kolom bertipe objek dengan sesuatu string/teks.*\n",
    "\n",
    "*Dalam sub bab ini akan mengganti missing value dengan nilai statistik kolom bersangkutan, baik median atau mean (nilai rata-rata). Misalnya akan menggunakan kolom active. Dengan mengabaikan terlebih dahulu sebaran berdasarkan negara (univariate), jika mengisi dengan nilai rata-rata maka **harus melihat terlebih dahulu data apakah memiliki outliers atau tidak. Jika ada outliers dari data maka menggunakan nilai tengah (median) data adalah cara yang lebih safe**.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Untuk itu diputuskan dengan mengecek nilai median dan nilai mean kolom active juga nilai min dan max-nya. Jika data pada kolom active terdistribusi normal maka nilai mean dan median akan hampir sama.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Contoh Cek Nilai Statistik Describe Kolom Active :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     949.000000\n",
       "mean      192.571128\n",
       "std       438.904950\n",
       "min        -6.000000\n",
       "25%         2.000000\n",
       "50%        41.000000\n",
       "75%       149.000000\n",
       "max      2243.000000\n",
       "Name: active, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\")\n",
    "\n",
    "df['active'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Terlihat data memiliki distribusi yang skewness, karena nilai mean dan median(50%) yang cukup jauh serta range data yang cukup lebar. Di sini pada kolom active data memiliki outliers. Jadi akan **mengisi missing value dengan median**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awal: mean = 192.571128, median = 41.000000.\n",
      "Fillna median: mean = 184.841000, median = 41.000000.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\")\n",
    "# Cetak nilai mean dan median awal \n",
    "print(\"Awal: mean = %f, median = %f.\" % (df[\"active\"].mean(), df['active'].median()))\n",
    "# Isi missing value kolom active dengan median\n",
    "df_median = df[\"active\"].fillna(df['active'].median())\n",
    "# Cetak nilai mean dan median awal setelah diisi dengan median\n",
    "print(\"Fillna median: mean = %f, median = %f.\" % (df_median.mean(), df_median.median()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treatment untuk Missing Value - Part 5**\n",
    "\n",
    "*Di bagian ini akan menggunakan teknik interpolasi dalam mengisi nilai missing value pada suatu dataset.*\n",
    "\n",
    "*Data yang menggunakan interpolasi untuk mengisi data yang hilang adalah **time series data, yang secara default akan diisi dengan interpolasi linear**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setelah diisi missing valuenya:\n",
      " 2020-01-01     9.0\n",
      "2020-01-02    14.0\n",
      "2020-01-05    19.0\n",
      "2020-01-07    24.0\n",
      "2020-01-10    27.0\n",
      "2020-01-12    30.0\n",
      "2020-01-15    33.0\n",
      "2020-01-17    36.5\n",
      "2020-01-16    40.0\n",
      "2020-01-20    45.0\n",
      "2020-01-22    52.0\n",
      "2020-01-25    75.0\n",
      "2020-01-28    75.0\n",
      "2020-01-30    75.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Data\n",
    "ts = pd.Series({\n",
    "   \"2020-01-01\":9,\n",
    "   \"2020-01-02\":np.nan,\n",
    "   \"2020-01-05\":np.nan,\n",
    "   \"2020-01-07\":24,\n",
    "   \"2020-01-10\":np.nan,\n",
    "   \"2020-01-12\":np.nan,\n",
    "   \"2020-01-15\":33,\n",
    "   \"2020-01-17\":np.nan,\n",
    "   \"2020-01-16\":40,\n",
    "   \"2020-01-20\":45,\n",
    "   \"2020-01-22\":52,\n",
    "   \"2020-01-25\":75,\n",
    "   \"2020-01-28\":np.nan,\n",
    "   \"2020-01-30\":np.nan\n",
    "})\n",
    "# Isi missing value menggunakan interpolasi linier\n",
    "ts = ts.interpolate()\n",
    "# Cetak time series setelah interpolasi linier\n",
    "print(\"Setelah diisi missing valuenya:\\n\", ts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Of Module**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dfae695991f40f7f711b859ebe4404a578ce2940a1c2f7058c1cb98bd497b2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
